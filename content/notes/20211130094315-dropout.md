+++
title = "Dropout"
author = ["Fangyuan"]
date = 2021-11-30
slug = "20211130094315-dropout"
tags = ["ml"]
draft = false
+++

If the relationship between the9 input and the correct output is complicated
and the network has enough hidden units to model it accurately, there
will typically be many <span class="underline">different settings of the weights</span> that can model
the training set almost perfectly, especially if there is only a limited
amount of labeled training data. Each of these weight vectors will make
<span class="underline">different predictions</span> on held-out test data and almost all of them will
do <span class="underline">worse on the test data</span> than on the training data because the feature
detectors have been tuned to <span class="underline">work well together on the training data</span> but
not on the test data.

The standard way to reduce error on the test set is to train many separate
networks and then apply each of these networks to the test data.

Overfitting also can be reduced by using "dropout" to prevent complex
co-adaptations( 参数之间的关联性 ) on the training data. On each presentation
of each training case, each hidden unit is <span class="underline">randomly omitted</span> from the network
with a probability of 0.5, so a hidden unit <span class="underline">cannot rely on</span> other hidden
units being present. It's also can prevent the weight from growing too
large.

At test time, they use the "mean network" that contains all of the hidden
units but with their outgoing weights <span class="underline">halved</span> to compensate for the fact
that twice as many of them are active.

Dropout is kind of like "bagging" in which different models are trained
on different random selections of cases from the training set and all
models are given equal weight in the combination(Like what did in
distributed ML). Dropout can be seen as an extreme form of bagging in
which each model is trained on a single case and each parameter of the
model is very strongly regularized by sharing it with the corresponding
parameter in all the other models.


## Useful references {#useful-references}

-   [Understanding Dropout](https://www.youtube.com/watch?v=ARq74QuavAo)
-   [Dropout Regulation](https://www.youtube.com/watch?v=D8PJAL-MZv8)
