+++
title = "Bootstrapping"
author = ["Fangyuan"]
date = 2022-01-18
slug = "20220118212041-bootstrapping"
draft = false
+++

[留出法]({{< relref "20220118164804-hold_out.md" >}})和[交叉验证法]({{< relref "20220118165430-cross_validation.md" >}})由于保留了一部分样本进行测试，因此实际使用的训练集比数据集要小，
这必然会引入一些因训练样本规模不同而导致的估计偏差。

有什么方法可以减少训练样本规模不同造成的影响，同时还能比较高效的进行实验估计呢？

所谓 Bootstrapping 即可放回采样，从数据集中可放回的采取与原数据集同样大小的数据进行测试。

该方法可用于数据集较小，难以划分有效训练/测试集的情况。然而，这种方法产生的数据集改变了
初始数据集的分布，会引入估计偏差。


## Links to this note {#links-to-this-note}

-   [Generalization Error]({{< relref "20220118213418-generalization_error.md" >}})

    >   学习器在训练集上的误差被称为训练误差（training error）或经验误差（empirical error）。
    > 在测试集上的误差被称为泛化误差。
